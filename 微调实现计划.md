# 手写文字擦除模型微调实现计划

## 1. 数据加载器设计

### 1.1 MixedErasingData类设计

基于现有的`ErasingData`类，创建一个`MixedErasingData`类，实现80%增强数据和20%原始数据的混合加载。

#### 核心功能：
1. 维护两个图像路径列表：原始图像和增强图像
2. 建立文件名映射关系
3. 在`__getitem__`方法中实现概率选择逻辑

#### 实现细节：

```python
class MixedErasingData(paddle.io.Dataset):
    def __init__(self, dataRoot, augmentedRoot, loadSize, training=True, mask_dir='mask', augmented_prob=0.8):
        super(MixedErasingData, self).__init__()
        # 原始图像路径
        self.originalFiles = [join(dataRootK, files) for dataRootK, dn, filenames in walk(dataRoot) 
                             for files in filenames if CheckImageFile(files)]
        
        # 增强图像路径
        self.augmentedFiles = [join(augmentedRootK, files) for augmentedRootK, dn, filenames in walk(augmentedRoot) 
                              for files in filenames if CheckImageFile(files)]
        
        # 构建文件名映射
        self.build_filename_mapping()
        
        self.loadSize = loadSize
        self.ImgTrans = ImageTransform()
        self.training = training
        self.mask_dir = mask_dir
        self.RandomCropparam = RandomCrop(self.loadSize)
        self.augmented_prob = augmented_prob
        
    def build_filename_mapping(self):
        """建立原始图像和增强图像的文件名映射关系"""
        self.original_to_augmented = {}
        self.augmented_to_original = {}
        
        # 从增强图像文件名中提取基础文件名
        for aug_path in self.augmentedFiles:
            filename = aug_path.split('/')[-1]
            # 去除_augmented后缀和扩展名
            base_name = filename.replace('_augmented.png', '')
            self.augmented_to_original[aug_path] = base_name
            
        # 为原始图像建立映射
        for orig_path in self.originalFiles:
            filename = orig_path.split('/')[-1]
            # 去除扩展名
            base_name = filename.replace('.jpg', '')
            self.original_to_augmented[orig_path] = base_name
            
    def __getitem__(self, index):
        # 根据概率选择使用增强图像还是原始图像
        use_augmented = random.random() < self.augmented_prob
        
        if use_augmented:
            # 使用增强图像
            img_path = self.augmentedFiles[index % len(self.augmentedFiles)]
            base_name = self.augmented_to_original[img_path]
            # 构建GT和mask路径
            gt_path = img_path.replace('augmented_images', 'gts').replace('_augmented.png', '.png')
            mask_path = img_path.replace('augmented_images', self.mask_dir).replace('_augmented.png', '.png')
        else:
            # 使用原始图像
            img_path = self.originalFiles[index % len(self.originalFiles)]
            base_name = self.original_to_augmented[img_path]
            # 构建GT和mask路径
            gt_path = img_path.replace('images', 'gts').replace('.jpg', '.png')
            mask_path = img_path.replace('images', self.mask_dir).replace('.jpg', '.png')
            
        # 加载图像
        img = Image.open(img_path)
        mask = Image.open(mask_path)
        gt = Image.open(gt_path)
        
        # 应用数据增强
        if self.training:
            all_input = [img, mask, gt]
            all_input = random_horizontal_flip(all_input)   
            all_input = random_rotate(all_input)
            img = all_input[0]
            mask = all_input[1]
            gt = all_input[2]
            
        # 随机裁剪
        param = self.RandomCropparam._get_param(img.convert('RGB'), self.loadSize)
        inputImage = F.crop(img.convert('RGB'), *param)
        maskIn = F.crop(mask.convert('RGB'), *param)
        groundTruth = F.crop(gt.convert('RGB'), *param)
        
        # 转换为tensor
        inputImage = self.ImgTrans(inputImage)
        maskIn = self.ImgTrans(maskIn)
        groundTruth = self.ImgTrans(groundTruth)
        
        # 返回文件名（用于调试）
        path = img_path.split('/')[-1]
        
        return inputImage, groundTruth, maskIn, path
    
    def __len__(self):
        # 返回较大的数据集大小，确保能遍历所有数据
        return max(len(self.originalFiles), len(self.augmentedFiles))
```

## 2. 微调数据目录结构

### 2.1 推荐目录结构

```
finetune_dataset/
├── images/              # 原始图像 (从 tran_add_up/images/ 复制)
├── augmented_images/    # 增强图像 (从 tran_add_up/augmented_images/ 复制)
├── gts/                 # GT图像 (从 tran_add_up/gts/ 复制)
└── mask/                # 生成的mask文件
```

### 2.2 数据准备脚本

创建一个数据准备脚本，完成以下任务：
1. 从`tran_add_up/`复制数据到`finetune_dataset/`
2. 为所有图像生成mask文件
3. 验证数据完整性

## 3. 微调训练脚本

### 3.1 修改现有train.py

基于现有的`train.py`，创建一个`train_finetune.py`，主要修改：

1. 导入`MixedErasingData`类
2. 修改数据加载器初始化
3. 添加微调特定参数

### 3.2 关键修改点

```python
# 导入混合数据加载器
from data.mixed_dataloader import MixedErasingData

# 替换原有的数据加载器
Erase_data = MixedErasingData(
    dataRoot='./finetune_dataset/images',
    augmentedRoot='./finetune_dataset/augmented_images', 
    loadSize=loadSize,
    training=True,
    mask_dir=args.mask_dir,
    augmented_prob=0.8  # 80%概率使用增强数据
)
```

## 4. 生成Mask文件

### 4.1 修改compute_mask.py

需要修改`compute_mask.py`脚本，使其能够：
1. 处理增强图像（PNG格式）
2. 为原始图像和增强图像都生成mask
3. 保存到统一的mask目录

### 4.2 Mask生成逻辑

```python
# 为原始图像生成mask
for img_path in original_images:
    gt_path = img_path.replace('images', 'gts').replace('.jpg', '.png')
    mask_path = img_path.replace('images', 'mask').replace('.jpg', '.png')
    compute_mask(img_path, gt_path, mask_path)
    
# 为增强图像生成mask
for img_path in augmented_images:
    gt_path = img_path.replace('augmented_images', 'gts').replace('_augmented.png', '.png')
    mask_path = img_path.replace('augmented_images', 'mask').replace('_augmented.png', '.png')
    compute_mask(img_path, gt_path, mask_path)
```

## 5. 微调参数配置

### 5.1 推荐参数

```bash
CUDA_VISIBLE_DEVICES=0 python3 train_finetune.py \
    --batchSize 4 \
    --dataRoot './finetune_dataset/images' \
    --augmentedRoot './finetune_dataset/augmented_images' \
    --net 'str' \                    # 初次微调使用STR模型
    --lr 5e-5 \                      # 使用较小的学习率
    --pretrained 'STE_str_best.pdparams' \  # 加载预训练模型
    --modelsSavePath 'ckpts_finetune_str' \
    --logPath 'logs_finetune_str' \
    --mask_dir 'mask' \
    --num_epochs 1000 \              # 较少的训练轮数
    --lr_decay_iters 100000 \
    --augmented_prob 0.8             # 80%概率使用增强数据
```

### 5.2 训练策略

1. **第一阶段**：使用预训练模型，冻结部分层，训练100个epoch
2. **第二阶段**：解冻所有层，使用更小学习率，训练900个epoch
3. **验证**：每5000次迭代进行验证，保存最佳模型

## 6. 实施步骤

### 6.1 数据准备
1. 等待`augment_images.py`运行完成
2. 创建`finetune_dataset`目录结构
3. 复制数据文件
4. 生成mask文件

### 6.2 代码实现
1. 创建`data/mixed_dataloader.py`
2. 创建`train_finetune.py`
3. 修改`compute_mask.py`

### 6.3 测试验证
1. 测试数据加载器
2. 运行小批量训练验证
3. 完整微调训练

## 7. 预期效果

通过80%增强数据和20%原始数据的混合训练，预期模型能够：
1. 更好地处理真实场景中的涂抹痕迹
2. 保持对原始手写文字的识别能力
3. 提高泛化能力，适应更多样的输入

## 8. 后续优化

1. 如果STR模型微调效果满意，可以尝试IDR模型
2. 调整增强数据比例（如70%/30%或90%/10%）
3. 尝试更复杂的数据增强策略
4. 使用学习率调度器优化训练过程