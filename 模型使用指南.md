# 手写文字擦除模型使用指南

## 目录

- [环境准备](#环境准备)
- [数据准备](#数据准备)
- [训练流程](#训练流程)
- [推理流程](#推理流程详解)
- [模型微调](#模型微调)
- [常见问题解答](#常见问题解答)
- [故障排除指南](#故障排除指南)

## 快速开始

### 1. 环境安装
```bash
# 安装PaddlePaddle
pip install paddlepaddle-gpu

# 安装其他依赖
pip install opencv-python pillow numpy scikit-image matplotlib
```

### 2. 快速推理
```bash
# 下载预训练模型到当前目录
# STE_idr_best.pdparams 和 STE_str_best.pdparams

# 使用混合模型进行推理
CUDA_VISIBLE_DEVICES=0 python test.py \
    --dataRoot '您的测试数据路径' \
    --batchSize 1 \
    --savePath 'results/' \
    --net 'mix'
```

### 3. 快速训练
```bash
# 准备数据集（images和gts文件夹）
# 生成mask
python compute_mask.py

# 开始训练
CUDA_VISIBLE_DEVICES=0 python3 train.py --batchSize 4 \
  --dataRoot './dataset/task2/dehw_train_dataset/images' \
  --net 'idr' \
  --lr 1e-4 \
  --modelsSavePath 'ckpts_idr' \
  --logPath 'logs'  \
  --mask_dir 'mask_331_25'
```

## 环境准备

### 系统要求
- Python 3.7+
- CUDA 10.1+ (推荐使用GPU训练和推理)
- 内存：至少8GB (推荐16GB+)

### 依赖安装

```bash
# 安装PaddlePaddle (GPU版本)
pip install paddlepaddle-gpu

# 或者安装CPU版本
pip install paddlepaddle

# 安装其他依赖
pip install opencv-python
pip install pillow
pip install numpy
pip install scikit-image
pip install matplotlib
```

### 项目结构
```
Baidu-netdisk-AI-Image-processing-Challenge-handwriting/
├── data/                   # 数据加载模块
│   └── dataloader.py      # 数据加载器
├── loss/                   # 损失函数模块
│   ├── Loss.py            # 主要损失函数
│   └── PSNRLoss.py        # PSNR损失
├── models/                 # 模型定义
│   ├── sa_gan.py          # STR模型
│   ├── sa_aidr.py         # IDR模型
│   ├── networks.py        # 网络组件
│   └── ...
├── ckpt_convert/           # 模型转换工具
├── train.py               # 训练脚本
├── test.py                # 测试脚本
├── train.sh               # 训练脚本启动
├── test.sh                # 测试脚本启动
├── augment_images.py      # 数据增强脚本，生成带涂抹痕迹的训练图像
├── compute_mask.py        # 生成mask文件
├── utils.py               # 工具函数
└── 模型使用指南.md          # 本文档
```

## 模型概述

本项目提供了两个预训练模型，用于手写文字擦除任务：

1. **STE_idr_best.pdparams** (86.8 MB) - IDR模型
   - 基于STRAIDR架构，包含Non-Local深度编解码结构
   - 特点：擦除质量更高，细节还原更好
   - 适用：对质量要求较高的场景

2. **STE_str_best.pdparams** (75.5 MB) - STR模型  
   - 基于STRnet2架构，改进的EraseNet版本
   - 特点：模型较小，推理速度更快
   - 适用：对速度要求较高的场景

## 数据准备

### 数据格式要求
训练数据需要包含以下三个文件夹：
- `images/`: 包含手写文字的原始图像
- `gts/`: 对应的干净背景图像（无手写文字）
- `mask/`: 手写文字区域的掩码图像

### 数据增强

为了提升模型在真实场景中的鲁棒性，项目提供了[`augment_images.py`](augment_images.py:1)脚本，用于在干净的手写图像上添加涂抹痕迹，生成更接近真实情况的训练数据。

**使用方法**：

1.  **准备数据**：确保您的数据目录结构如下：
    ```
    tran_add_up/
    ├── images/        # 原始手写图像 (JPG)
    ├── gts/           # 对应的干净背景图像 (PNG)
    └── strokes/       # 涂抹痕迹的透明PNG文件
    ```

2.  **运行增强脚本**：
    ```bash
    python augment_images.py
    ```
    脚本会自动在 `tran_add_up/` 目录下创建 `augmented_images/` 文件夹，其中包含带有随机涂抹痕迹的合成图像。

**增强策略**：
- 脚本会检测手写文字区域。
- 随机选择80%的手写文字区域进行涂抹覆盖。
- 涂抹痕迹会进行随机的缩放、旋转和位置调整，以增加多样性。
- 优先使用大尺寸涂抹图像进行裁切，避免过度拉伸导致的像素化。

### 生成Mask文件

在训练前，需要先生成mask文件。项目提供了[`compute_mask.py`](compute_mask.py:1)脚本来自动生成mask：

```bash
# 修改compute_mask.py中的路径
path = './custom_train_dataset'  # 训练数据路径
save_path = './custom_train_dataset/mask/'  # mask保存路径

# 运行脚本生成mask
python compute_mask.py
```

**Mask生成原理**：
- 计算原始图像和干净图像的RGB通道差值
- 平均差值大于25的像素设为需要擦除区域
- 对mask进行腐蚀操作，减少边缘噪声
- 最终mask中白色区域表示需要保留，黑色区域表示需要擦除

### 数据增强
训练时使用以下数据增强策略：
- 随机水平翻转（30%概率）
- 随机小角度旋转（-10°到+10°，30%概率）
- 随机裁剪为512×512大小

## 使用方法

### 1. 单独使用IDR模型

```bash
CUDA_VISIBLE_DEVICES=0 python test.py \
    --dataRoot '您的测试数据路径' \
    --batchSize 1 \
    --savePath 'results_idr/' \
    --net 'idr'
```

### 2. 单独使用STR模型

```bash
CUDA_VISIBLE_DEVICES=0 python test.py \
    --dataRoot '您的测试数据路径' \
    --batchSize 1 \
    --savePath 'results_str/' \
    --net 'str'
```

### 3. 混合使用（推荐）

```bash
CUDA_VISIBLE_DEVICES=0 python test.py \
    --dataRoot '您的测试数据路径' \
    --batchSize 1 \
    --savePath 'results_mix/' \
    --net 'mix'
```

## 训练流程

### 训练脚本说明

项目提供了[`train.py`](train.py:1)训练脚本和[`train.sh`](train.sh:1)启动脚本。

### 训练参数详解

```bash
python train.py \
    --batchSize 4 \                    # 批处理大小
    --dataRoot './dataset/task2/dehw_train_dataset/images' \  # 训练数据路径
    --net 'idr' \                     # 模型类型：'str'或'idr'
    --lr 1e-4 \                       # 学习率
    --modelsSavePath 'ckpts_str_m331_25_idr' \  # 模型保存路径
    --logPath 'logs' \                # 日志保存路径
    --mask_dir 'mask_331_25' \        # mask文件夹名称
    --num_epochs 5000 \               # 训练轮数
    --loadSize 512 \                  # 图像加载大小
    --numOfWorkers 16 \               # 数据加载进程数
    --gamma 0.5 \                     # 学习率衰减因子
    --lr_decay_iters 400000 \         # 学习率衰减间隔
    --seed 2022                       # 随机种子
```

### 训练流程详解

1. **数据加载**：
   - 使用[`ErasingData`](data/dataloader.py:65)类加载训练数据
   - 自动应用数据增强（翻转、旋转、裁剪）
   - 验证数据使用[`devdata`](data/dataloader.py:112)类加载

2. **模型初始化**：
   - STR模型：[`STRnet2`](models/sa_gan.py:37)
   - IDR模型：[`STRAIDR`](models/sa_aidr.py:43)
   - 支持从预训练模型继续训练

3. **损失函数**：
   - 使用[`LossWithGAN_STE`](loss/Loss.py:50)损失函数
   - 包含L1损失和Dice损失
   - 两阶段训练策略

4. **优化器**：
   - Adam优化器
   - 学习率阶梯式衰减

5. **验证和保存**：
   - 每5000次迭代进行验证
   - 计算PSNR指标
   - 保存最佳模型和定期检查点

### 训练命令示例

```bash
# 训练IDR模型
CUDA_VISIBLE_DEVICES=0 python3 train.py --batchSize 4 \
  --dataRoot './dataset/task2/dehw_train_dataset/images' \
  --net 'idr' \
  --lr 1e-4 \
  --modelsSavePath 'ckpts_idr' \
  --logPath 'logs'  \
  --mask_dir 'mask_331_25'

# 训练STR模型
CUDA_VISIBLE_DEVICES=0 python3 train.py --batchSize 4 \
  --dataRoot './dataset/task2/dehw_train_dataset/images' \
  --net 'str' \
  --lr 1e-4 \
  --modelsSavePath 'ckpts_str' \
  --logPath 'logs'  \
  --mask_dir 'mask_331_25'
```

### 训练监控

训练过程中会在日志中记录：
- 每次迭代的损失值
- 学习率变化
- 验证集PSNR指标
- 最佳模型保存信息

## 参数说明

- `--dataRoot`: 测试数据文件夹路径
- `--batchSize`: 批处理大小，建议设置为1以保证质量
- `--savePath`: 结果保存路径
- `--net`: 模型选择，可选值：
  - `idr`: 使用IDR模型
  - `str`: 使用STR模型
  - `mix`: 使用两个模型的融合结果（推荐）

## 重要注意事项

1. **数据格式要求**：
   - 输入图像应为常见格式（JPG、PNG等）
   - 建议图像分辨率不要太小，否则可能影响效果

2. **性能考虑**：
   - IDR模型质量更好但速度较慢
   - STR模型速度更快但质量略低
   - 混合模式质量最佳但耗时最长

3. **真实场景应用**：
   - 模型是在合成数据上训练的，在真实场景中效果可能不如比赛数据集
   - 如需在真实场景中使用，建议在私有数据上进行微调

## 推理流程详解

### 推理脚本说明

项目提供了[`test.py`](test.py:1)推理脚本和[`test.sh`](test.sh:1)启动脚本。

### 推理参数详解

```bash
python test.py \
    --dataRoot '../data/dehw_testB_dataset' \  # 测试数据路径
    --batchSize 1 \                           # 批处理大小（建议设为1）
    --savePath 'res/' \                       # 结果保存路径
    --net 'mix' \                             # 模型类型：'str'、'idr'或'mix'
    --loadSize 512 \                          # 图像处理大小
    --numOfWorkers 0 \                        # 数据加载进程数
```

### 推理流程详解

1. **模型加载**：
   - 根据`--net`参数加载对应模型
   - STR模型：加载`STE_str_best.pdparams`
   - IDR模型：加载`STE_idr_best.pdparams`
   - 混合模式：同时加载两个模型并融合结果

2. **图像预处理**：
   - 图像反射填充（pad=106像素）
   - 分块处理：将大图像分割为300×300的小块
   - 重叠区域处理：确保边缘区域质量

3. **推理策略**：
   - **单模型推理**：直接使用STR或IDR模型
   - **混合推理**：两个模型结果平均，质量最佳
   - **镜像增强**：对每个块进行水平镜像并取平均，提升质量

4. **后处理**：
   - 移除填充区域
   - 转换图像格式并保存

### 推理命令示例

```bash
# 使用IDR模型推理
CUDA_VISIBLE_DEVICES=0 python test.py \
    --dataRoot '您的测试数据路径' \
    --batchSize 1 \
    --savePath 'results_idr/' \
    --net 'idr'

# 使用STR模型推理
CUDA_VISIBLE_DEVICES=0 python test.py \
    --dataRoot '您的测试数据路径' \
    --batchSize 1 \
    --savePath 'results_str/' \
    --net 'str'

# 使用混合模型推理（推荐）
CUDA_VISIBLE_DEVICES=0 python test.py \
    --dataRoot '您的测试数据路径' \
    --batchSize 1 \
    --savePath 'results_mix/' \
    --net 'mix'
```

### 推理优化技巧

1. **内存优化**：
   - 使用较小的`batchSize`（建议为1）
   - 分块处理大图像，避免内存溢出

2. **速度优化**：
   - 使用STR模型而非IDR模型
   - 减少分块大小（但可能影响质量）

3. **质量优化**：
   - 使用混合模式（`--net 'mix'`）
   - 确保输入图像分辨率足够高

## 输出结果

处理后的图像将保存在指定路径下的两个文件夹中：
- `WithMaskOutput/`: 带掩码的输出结果
- `StrOuput/`: 直接输出结果

## 模型微调

### 高级微调流程（推荐）

当需要在特定数据集上获得最佳性能时，我们强烈推荐使用此高级微调策略。它通过一系列自动化脚本，彻底解决了数据准备中的常见陷阱（如数据不匹配、泄漏），并提供了强大的混合数据训练能力。

### 微调优势
- **数据完整性保证**: `prepare_finetune_dataset.py` 脚本会严格验证并确保所有训练和验证数据都拥有完整的图像、增强图和真值（GT）三元组，从根本上杜绝了因文件缺失导致的训练中断。
- **全自动化流程**: 从数据清洗、校验到验证集划分，一键完成，无需手动操作，极大降低了出错风险。
- **鲁棒性更强**: 通过 `--augmented_prob` 参数灵活控制原始图像和增强图像的混合比例，模型可以同时学习两种数据分布，显著提高泛化能力。
- **可靠的模型选择**: 独立的验证集可以客观评估模型的性能，帮助我们选择最优的模型，有效防止过拟合。
- **内存高效**: 支持梯度累积，可在不增加显存的情况下模拟大批次训练，提升收敛稳定性。

### 微调步骤

**1. 准备初始数据**

将你的数据放入 `tran_add_up` 文件夹，并确保其结构如下：
```
tran_add_up/
├── images/        # 原始手写图像 (JPG)
├── gts/           # 对应的干净背景图像 (PNG)
└── strokes/       # 用于生成涂抹痕迹的透明PNG文件
```

**2. 生成增强数据**

运行数据增强脚本，这将在 `tran_add_up/` 目录下创建一个 `augmented_images/` 文件夹。
```bash
python augment_images.py
```

**3. 准备、清洗并划分数据集**

这是最关键的一步。首先，手动创建一个名为 `finetune_dataset` 的目录，并将 `tran_add_up` 目录下的 `images/`, `gts/`, 和 `augmented_images/` 这三个文件夹**复制**到 `finetune_dataset/` 中。

然后，运行 `prepare_finetune_dataset.py` 脚本。它会自动完成以下工作：
- 清理所有没有对应 `gts` 文件的 "孤儿" 图像。
- 从原始图像中随机抽取一部分（默认为80张）作为验证集，并移动到 `val_images/` 和 `val_gts/`。
- 再次检查并清理增强图像，确保所有训练用的图像都有对应的 `gts` 文件。

```bash
# 确保 finetune_dataset 目录已按上述说明准备好
python prepare_finetune_dataset.py
```

**4. 生成Mask文件**

为所有训练和验证图像生成掩码（mask）。脚本会自动处理所有子目录。
```bash
python compute_mask.py
```
生成的 masks 会保存在 `finetune_dataset/mask/` 目录下。

**5. 开始微调训练**

使用专门的 `train_finetune.py` 脚本开始训练。它支持混合数据加载、周期性验证和梯度累积。

```bash
python3 train_finetune.py \
    --dataRoot './finetune_dataset/images' \
    --augmentedRoot './finetune_dataset/augmented_images' \
    --mask_dir 'mask' \
    --net 'idr' \
    --pretrained 'STE_idr_best.pdparams' \
    --modelsSavePath 'ckpts_finetune' \
    --logPath 'logs_finetune' \
    --batchSize 4 \
    --accumulation_steps 4 \
    --numOfWorkers 16 \
    --num_epochs 1000 \
    --lr 5e-5 \
    --lr_decay_iters 20000 \
    --augmented_prob 0.8
```

**重要参数说明:**
- `--augmentedRoot`: 指向增强图像（`augmented_images`）的路径。
- `--augmented_prob`: 从增强数据集中采样的概率（例如，0.8 表示80%的数据来自增强集）。
- `--batchSize`: 单次前向传播的批处理大小。请根据你的GPU显存大小调整。
- `--accumulation_steps`: **梯度累积步数**。通过累积多个小批次的梯度来模拟更大的批次大小。**有效批次大小 = batchSize × accumulation_steps**。例如，`batchSize=4` 和 `accumulation_steps=4` 等效于 `batchSize=16` 的训练效果，但显存占用仅为 `batchSize=4` 的水平。

### 微调技巧

1. **学习率调整**：
   - 使用比原始训练更小的学习率（如5e-5）
   - 可以尝试学习率调度策略

2. **数据增强**：
   - 根据数据特点调整增强策略
   - 真实场景可能需要更强的增强

3. **训练监控**：
   - 密切监控验证集指标
   - 防止过拟合，及时停止训练

4. **两阶段训练**：
   - 第一阶段：使用预训练模型，冻结部分层
   - 第二阶段：解冻更多层，使用更小学习率

### 微调评估

```bash
# 使用验证集评估微调效果
python test.py \
    --dataRoot './custom_dataset/val_images' \
    --batchSize 1 \
    --savePath 'results_finetune/' \
    --net 'idr'

# 对比微调前后的效果
```

### 传统微调流程（不推荐）

如果您不使用混合数据训练，也可以使用传统的 `train.py` 脚本，但需要手动准备数据，且容易遇到数据不完整或划分不当的问题。

**警告**：此方法繁琐且容易出错，我们强烈建议使用上述的高级微调流程。

```bash
# 手动准备数据（不推荐）
mkdir -p custom_train_dataset/images
mkdir -p custom_train_dataset/gts
cp -r tran_add_up/images/* custom_train_dataset/images/
cp -r tran_add_up/gts/* custom_train_dataset/gts/
# 注意：此方法默认不使用增强图像，且需要手动划分验证集和生成mask
python compute_mask.py  # 需要修改脚本路径

# 使用原始训练脚本微调
CUDA_VISIBLE_DEVICES=0 python3 train.py \
    --batchSize 4 \
    --dataRoot './custom_train_dataset/images' \
    --net 'idr' \
    --lr 5e-5 \
    --pretrained 'STE_idr_best.pdparams' \
    --modelsSavePath 'ckpts_finetune_legacy' \
    --logPath 'logs_finetune_legacy' \
    --mask_dir 'mask' \
    --num_epochs 1000 \
    --lr_decay_iters 100000
```

## 常见问题解答

### 训练相关问题

**Q1: 训练过程中出现CUDA内存不足怎么办？**
A1: 可以尝试以下解决方案：
- **使用梯度累积**：保持较小的`batchSize`（如4），同时设置较大的`--accumulation_steps`（如4），以获得大批次训练的效果，而显存占用保持小批次水平。
- 减小`batchSize`参数（如从4减到2或1）
- 减小`loadSize`参数（如从512减到256）
- 减少数据加载进程数`numOfWorkers`
- 使用CPU模式：`paddle.set_device('cpu')`

**Q2: 训练损失不下降或下降很慢？**
A2: 可能的原因和解决方案：
- 检查学习率设置，尝试调整`--lr`参数
- 确认数据路径和mask路径正确
- 检查数据质量，确保images、gts和mask对应
- 尝试使用预训练模型进行微调

**Q3: 如何判断模型是否训练完成？**
A3: 观察以下指标：
- 验证集PSNR不再提升
- 训练损失趋于稳定
- 日志中显示保存了最佳模型

### 推理相关问题

**Q4: 推理结果质量不佳怎么办？**
A4: 尝试以下优化方法：
- 使用混合模式`--net 'mix'`
- 确保输入图像分辨率足够高
- 检查图像格式和质量
- 考虑在相似数据上微调模型

**Q5: 推理速度太慢如何优化？**
A5: 可以尝试：
- 使用STR模型而非IDR模型
- 增加分块大小（但可能影响质量）
- 使用更强大的GPU
- 减少镜像增强步骤

**Q6: 推理时出现错误怎么办？**
A6: 常见错误排查：
- 检查模型文件是否存在且完整
- 确认数据路径正确
- 检查图像格式是否支持
- 查看错误日志定位问题

### 环境配置问题

**Q7: PaddlePaddle安装失败？**
A7: 解决方案：
- 确认Python版本兼容性
- 检查CUDA版本匹配
- 尝试使用清华源：`pip install -i https://pypi.tuna.tsinghua.edu.cn/simple paddlepaddle-gpu`

**Q8: 模型加载失败？**
A8: 可能原因：
- 模型文件损坏或不完整
- PaddlePaddle版本不匹配
- 模型路径错误

### 数据相关问题

**Q9: 微调数据准备失败，提示找不到文件怎么办？**
A9: 这通常是由于数据不完整或路径错误导致的。**请严格按照[高级微调流程](#高级微调流程推荐)操作**：
1. **不要手动复制文件**，直接运行 `python prepare_finetune_dataset.py`，它会自动处理所有问题。
2. 确保运行 `python compute_mask.py` 生成所有必需的mask文件。
3. 检查 `finetune_dataset` 目录下是否包含了 `images/`, `augmented_images/`, `gts/`, `val_images/`, `val_gts/` 和 `mask/` 所有文件夹。

**Q10: 如何准备自己的训练数据？**
A10: 数据准备步骤：
1. 准备images文件夹（带手写文字的图像）
2. 准备gts文件夹（对应的干净图像）
3. 运行`compute_mask.py`生成mask
4. 确保文件名对应一致

**Q11: 数据增强如何调整？**
A11: 可以修改`data/dataloader.py`中的增强策略：
- 调整翻转概率
- 修改旋转角度范围
- 添加其他增强方法
- **更推荐**：使用 `train_finetune.py` 的 `--augmented_prob` 参数控制增强数据比例。

## 故障排除指南

### 常见错误及解决方案

1. **ImportError: No module named 'paddle'**
   - 重新安装PaddlePaddle
   - 检查Python环境

2. **CUDA out of memory**
   - 减小batchSize
   - 使用CPU模式
   - 减小图像尺寸

3. **FileNotFoundError: [Errno 2] No such file or directory**
   - 检查文件路径
   - 确认文件存在
   - 检查文件权限

4. **RuntimeError: Expected all tensors to be on the same device**
   - 检查GPU/CPU设置
   - 确保模型和数据在同一设备

### 性能优化建议

1. **训练优化**：
   - 使用多GPU训练
   - 增加数据加载进程数
   - 使用混合精度训练
   - **使用梯度累积**：在不增加显存的情况下模拟更大的批次大小，通常能提升模型收敛的稳定性和最终效果。

2. **推理优化**：
   - 模型量化
   - 批量推理
   - 使用TensorRT加速

## 技术支持

如遇到问题，请按以下步骤排查：

1. **环境检查**：
   - PaddlePaddle版本是否正确安装
   - CUDA环境是否正确配置
   - Python依赖是否完整

2. **数据检查**：
   - 模型文件是否完整下载
   - 数据路径是否正确
   - 数据格式是否符合要求

3. **日志分析**：
   - 查看训练/推理日志
   - 定位具体错误信息
   - 分析资源使用情况

4. **社区支持**：
   - 查看项目Issues
   - 参考相关文档
   - 提交问题描述

## 版本更新记录

- v1.0: 初始版本，支持STR和IDR模型
- v1.1: 添加混合推理模式
- v1.2: 优化训练流程和推理速度
- v1.3: 完善文档和故障排除指南

## 总结

本手写文字擦除模型提供了完整的训练和推理解决方案，主要特点包括：

1. **双模型架构**：
   - STR模型：速度快，适合实时应用
   - IDR模型：质量高，适合对质量要求高的场景
   - 混合模式：结合两者优势，效果最佳

2. **灵活的训练流程**：
   - 支持从零开始训练
   - 支持预训练模型微调
   - 完善的验证和保存机制

3. **高效的推理策略**：
   - 分块处理大图像
   - 镜像增强提升质量
   - 内存优化设计

4. **广泛的应用场景**：
   - 试卷手写文字擦除
   - 文档清理和修复
   - 图像预处理

### 最佳实践建议

1. **数据准备**：
   - 确保训练数据质量
   - 合理生成mask
   - 适当的数据增强

2. **训练策略**：
   - 使用预训练模型加速收敛
   - 监控验证指标避免过拟合
   - 根据数据特点调整参数

3. **推理优化**：
   - 根据需求选择合适的模型
   - 优化分块策略平衡速度和质量
   - 在真实场景数据上微调

### 未来改进方向

1. **模型优化**：
   - 轻量化模型设计
   - 更高效的推理架构
   - 多模态融合

2. **应用扩展**：
   - 支持更多文字类型
   - 适应更多场景
   - 实时处理能力

3. **工程优化**：
   - 模型量化和压缩
   - 移动端部署
   - 服务化封装

---

**注意**：本模型主要在合成数据上训练，在真实场景中可能需要微调以获得最佳效果。建议根据具体应用场景调整训练策略和参数。

**联系方式**：如有问题或建议，请通过项目Issues或社区渠道反馈。